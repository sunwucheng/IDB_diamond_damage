{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classification.ipynb","provenance":[],"collapsed_sections":["_geBnJFbqqlH"],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 0 Load dataset"],"metadata":{"id":"cMu9abpGs_JD"}},{"cell_type":"code","metadata":{"id":"4yEDh1LuNZgK"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_path = '/content/drive/MyDrive/IDB_diamond_damage'"],"metadata":{"id":"oUjzAlRshXQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from tqdm import tqdm\n","from PIL import Image"],"metadata":{"id":"v7KphE9Mv6Yn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset(dataset_path):\n","  image_list = []\n","  label_list = []\n","  tag = 0\n","  category_names = os.listdir(dataset_path)\n","  category_nums = len(category_names)\n","  category_names.sort()\n","  print(category_names)\n","  for category in category_names:\n","    category_path = os.path.join(dataset_path, category)\n","    file_names = os.listdir(category_path)\n","    file_nums = len(file_names)\n","    file_names.sort()  \n","    for file in tqdm(file_names):\n","      file_path = os.path.join(category_path, file)\n","      image = Image.open(file_path)\n","      img = np.asarray(image,dtype=\"float32\")\n","\n","      #chose wheather to crop the images, e.g., 1024*1024\n","      img = img[0:1024, 0:1024]\n","      \n","      img = img[:, :, np.newaxis] \n","      image_list.append(img)\n","      label_list.append(tag)\n","    tag += 1\n","  return image_list, label_list"],"metadata":{"id":"spfxi2_nCTFZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_set, Y_set = load_dataset(os.path.join(PROJECT_path, 'SEM'))"],"metadata":{"id":"qi8DixSGVMsv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CLASS_num = 65\n","CLASS = [\"#01\", \"#02\", \"#03\", \"#04\", \"#05\", \"#06\", \"#07\", \"#08\", \"#09\", \"#10\", \"#11\", \"#12\", \"#13\", \"#14\", \"#15\", \"#16\", \"#17\", \"#18\", \"#19\", \"#20\", \"#21\", \"#22\", \"#23\", \"#24\", \"#25\", \"#26\", \"#27\", \"#28\", \"#29\", \"#30\", \"#31\", \"#32\", \"#33\", \"#34\", \"#35\", \"#36\", \"#37\", \"#38\", \"#39\", \"#40\", \"#41\", \"#42\", \"#43\", \"#44\", \"#45\", \"#46\", \"#47\", \"#48\", \"#49\", \"#50\", \"#51\", \"#52\", \"#53\", \"#54\", \"#55\", \"#56\", \"#57\", \"#58\", \"#59\", \"#60\", \"#61\", \"#62\", \"#63\", \"#64\", \"#65\"]"],"metadata":{"id":"1mtzF3dew6yt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["save_dir = os.path.join(PROJECT_path, 'saved_models')\n","if not os.path.isdir(save_dir):\n","  os.makedirs(save_dir)"],"metadata":{"id":"Lndo-6qcPMZ1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 Dataset processing"],"metadata":{"id":"NOeNn80TevBs"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"artrME5Pw1mN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def classification_dataset_process(X_set, Y_set):\n","  \n","  # choose the size to convert, e.g., 224*224\n","  X_set = [cv2.cvtColor(cv2.resize(i, (224, 224)), cv2.COLOR_GRAY2RGB) for i in X_set]\n","\n","  X_set = np.asarray(X_set)\n","  X_set = X_set.astype('float32')\n","  X_set /= 255.0\n","  Y_set = tf.keras.utils.to_categorical(Y_set, CLASS_num)\n","  return X_set, Y_set"],"metadata":{"id":"WNCwQK9uTZBN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_set, Y_set = classification_dataset_process(X_set, Y_set)"],"metadata":{"id":"pRhyck-oxUme"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, Y_train, Y_test = train_test_split(X_set,Y_set,random_state = 888)"],"metadata":{"id":"TbiXO91fvUqz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 VGG16 classification model"],"metadata":{"id":"HERG9dZ_W-R7"}},{"cell_type":"markdown","source":["## 2.1 [A] model establishment - DIY"],"metadata":{"id":"_geBnJFbqqlH"}},{"cell_type":"code","source":["# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\n","# from keras.models import Sequential, Model"],"metadata":{"id":"PPpT5vt-XPA9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = Sequential()\n","\n","# # Block_1\n","# model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu', input_shape=X_train.shape[1:]))\n","# model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n","# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","# # Block_2\n","# model.add(Conv2D(128, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(128, (3, 3), padding = 'same', activation='relu'))\n","# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","# # Block_3\n","# model.add(Conv2D(256, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(256, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(256, (3, 3), padding = 'same', activation='relu'))\n","# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","# # Block_4\n","# model.add(Conv2D(512, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(512, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(512, (3, 3), padding = 'same', activation='relu'))\n","# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","# # Block_5\n","# model.add(Conv2D(512, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(512, (3, 3), padding = 'same', activation='relu'))\n","# model.add(Conv2D(512, (3, 3), padding = 'same', activation='relu'))\n","# model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n","\n","# # Block_6\n","# model.add(Flatten())\n","# model.add(Dense(4096, activation='relu'))\n","# model.add(Dense(4096, activation='relu'))\n","# model.add(Dense(CLASS_num, activation='softmax'))"],"metadata":{"id":"ExAgnFZqqeei"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.1 [B] Model establishment - Import"],"metadata":{"id":"eaSNN6MDqe0I"}},{"cell_type":"code","source":["from keras import applications\n","from keras.layers import Flatten, Dense, Dropout, Activation\n","from keras.models import Sequential, Model"],"metadata":{"id":"jMTXZ5HIzXtD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model = applications.vgg16.VGG16(include_top=False, weights='imagenet', input_shape=X_train.shape[1:])\n","print(base_model.output)\n","model = Sequential()\n","model.add(Flatten(input_shape=base_model.output_shape[1:]))\n","\n","# add the rest layers\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","\n","model.add(Dense(CLASS_num, activation='softmax'))\n","model=Model(inputs=base_model.input, outputs=model(base_model.output))"],"metadata":{"id":"yn5uoa_2W9YH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transfer learning or not\n","for layer in base_model.layers:\n","  layer.trainable=False"],"metadata":{"id":"MwQkKTz4hhF2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2 Model compiling"],"metadata":{"id":"ywrVFSYB3CZC"}},{"cell_type":"code","source":["from keras.models import Model"],"metadata":{"id":"TdETRQN6e4V8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# choose approriate optimizer, loss function\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6), \n","       loss='categorical_crossentropy', \n","       metrics=['accuracy'])"],"metadata":{"id":"JW7R1tbP3LKd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.3 Model training\n","\n"],"metadata":{"id":"O8WBm1iPrtc9"}},{"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.models import Model\n","from keras.preprocessing.image import ImageDataGenerator"],"metadata":{"id":"7jGFjqG4zUf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# set hyper-parameters\n","epochs = 100\n","batch_size = 10\n","\n","# whether or not make data augmentation \n","data_augmentation = True\n","\n","# whether or not apply early stopping\n","early_stopping = False\n","if not early_stopping:\n","  callbacks = None\n","else:\n","  callbacks = [EarlyStopping(monitor='val_loss', patience=10)]"],"metadata":{"id":"lF855RFFYVU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not data_augmentation:\n","  print('Not using data augmentation.')\n","  history = model.fit(X_train, Y_train, \n","             batch_size=batch_size, \n","             epochs=epochs, \n","             validation_data=(X_test, Y_test), \n","             shuffle=True, \n","             callbacks=callbacks)\n","else:\n","  print('Using real-time data augmentation.')\n","  datagen = ImageDataGenerator(featurewise_center=False,  \n","                  samplewise_center=False,  \n","                  featurewise_std_normalization=False,  \n","                  samplewise_std_normalization=False, \n","                  zca_whitening=False, \n","                  zca_epsilon=1e-06, \n","                  rotation_range=0, \n","                  width_shift_range=0.1,\n","                  height_shift_range=0.1,\n","                  shear_range=0., \n","                  zoom_range=0.,\n","                  channel_shift_range=0., \n","                  fill_mode='nearest',\n","                  cval=0., \n","                  horizontal_flip=True, \n","                  vertical_flip=True, \n","                  rescale=None,\n","                  preprocessing_function=None,\n","                  data_format=None,\n","                  validation_split=0.0)\n","  datagen.fit(X_train)\n","  history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),  \n","                  epochs=epochs, \n","                  steps_per_epoch=X_train.shape[0]//batch_size, \n","                  validation_data=(X_test, Y_test), \n","                  workers=10,\n","                  callbacks=callbacks)"],"metadata":{"id":"6DSwjmaECn_A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.4 Model preservation"],"metadata":{"id":"y3Yg7FXiCT-V"}},{"cell_type":"code","source":["import os\n","from keras.models import Model"],"metadata":{"id":"fhnwyYnri918"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = os.path.join(save_dir, \"classification_model.h5\")\n","model.save(model_path)\n","model.summary()\n","print('Classification model saved at %s ' % model_path)"],"metadata":{"id":"AMt7j1CCTVoF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5 Training curves"],"metadata":{"id":"zN7QRg577Paz"}},{"cell_type":"code","source":["import os\n","import matplotlib.pyplot as plt"],"metadata":{"id":"U-jaPBKeJ3ZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot Accuracy-Epoch \n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model Accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train set', 'Validation set'], loc='upper left')\n","plt.savefig(os.path.join(save_dir, 'model_accuracy.png'))\n","plt.show()"],"metadata":{"id":"KsYRHXwM62bZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot Loss-Epoch\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model Loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train set', 'Validation set'], loc='upper left')\n","plt.savefig(os.path.join(save_dir, 'model_loss.png'))\n","plt.show()"],"metadata":{"id":"PTYNgHstes5y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.6 Model prediction"],"metadata":{"id":"3-qxtb1je22x"}},{"cell_type":"code","source":["from keras.models import Model"],"metadata":{"id":"REePAMcIjRl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_test_pred=model.predict(X_test)\n","print(Y_test_pred)"],"metadata":{"id":"VyWqax4Oe5pT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.7 Confusion matrix"],"metadata":{"id":"nOKFJNgI70yd"}},{"cell_type":"code","source":["import itertools\n","import numpy as np\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"jaHD922cLF31"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.7.1 Prediction results on test set"],"metadata":{"id":"bZeGvEqig5R6"}},{"cell_type":"code","source":["Y_test_true_label = []\n","for i in range(len(Y_test)):\n","  n = np.argmax(Y_test[i])\n","  Y_test_true_label.append(n)\n","\n","Y_test_pred_label = []\n","for i in range(len(Y_test_pred)):\n","  n = np.argmax(Y_test_pred[i])\n","  Y_test_pred_label.append(n)"],"metadata":{"id":"zwjlI0HA707Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Y_test_true_label)\n","print(Y_test)\n","print(Y_test_pred_label)\n","print(Y_test_pred)"],"metadata":{"id":"wcvKpBDbhvks"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.7.2 [A] Confusion matrix"],"metadata":{"id":"NgeHLyler64i"}},{"cell_type":"code","source":["def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=plt.cm.Greens, normalize=True):    \n","  accuracy = np.trace(cm) / float(np.sum(cm))\n","  misclass = 1 - accuracy\n","  if cmap is None:\n","    cmap = plt.get_cmap('Blues')\n","  plt.figure(figsize=(30, 30))   # (15,12)\n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  plt.title(title)\n","  plt.colorbar()\n","  if target_names is not None:\n","    tick_marks = np.arange(len(target_names))\n","    plt.xticks(tick_marks, target_names, rotation=45)\n","    plt.yticks(tick_marks, target_names)\n","  if normalize:\n","    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","  thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    if normalize:\n","      plt.text(j, i, \"{:0.4f}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","    else:\n","      plt.text(j, i, \"{:,}\".format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n","  plt.savefig(os.path.join(save_dir, \"confusion_matrixA.png\"), dpi=350)\n","  plt.show()"],"metadata":{"id":"lg3cDbiCKQuT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" def plot_conf(y_pre, y_val, labels):\n","  conf_mat = confusion_matrix(y_true=y_val, y_pred=y_pre)\n","  print(conf_mat)\n","  plot_confusion_matrix(conf_mat, normalize=False, target_names=labels, title='Confusion Matrix')"],"metadata":{"id":"Gc4E49xxhyeF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["C = confusion_matrix(Y_test_true_label, Y_test_pred_label)\n","plot_conf(Y_test_pred_label, Y_test_true_label, CLASS)"],"metadata":{"id":"s9xkr1JCh0Su"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.7.2 [B] Confusion matrix"],"metadata":{"id":"VcjdbE1Cr_6v"}},{"cell_type":"code","source":["def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.jet):\n","  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  \n","  if cmap is None:\n","    cmap = plt.get_cmap('Blues')\n","  plt.figure(figsize=(15, 12))   # (15,12)   \n","  plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","  plt.title(title)\n","  plt.colorbar()\n","  tick_marks = np.arange(len(classes))\n","  plt.xticks(tick_marks, classes, rotation=45)\n","  plt.yticks(tick_marks, classes)\n","  thresh = cm.max() / 2.\n","  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","    plt.text(j, i, '{:.2f}'.format(cm[i, j]), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n","  plt.tight_layout()\n","  plt.ylabel('True label')\n","  plt.xlabel('Predicted label')\n","  plt.savefig(os.path.join(save_dir, \"confusion_matrixB.png\"), dpi=350)\n","  plt.show()"],"metadata":{"id":"iqAlVXzIVJ5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_confuse(model, x_val, y_val):\n","  # predictions = model.predict_classes(x_val)\n","  predictions = np.argmax(model.predict(x_val),axis=1)\n","  truelabel = y_val.argmax(axis=-1) \n","  conf_mat = confusion_matrix(y_true=truelabel, y_pred=predictions)\n","  plt.figure()\n","  plot_confusion_matrix(conf_mat, range(np.max(truelabel)+1))"],"metadata":{"id":"GI4Fvz6Nh2n4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_test.shape)\n","print(Y_test.shape)\n","plot_confuse(model, X_test, Y_test)"],"metadata":{"id":"f3pNwgxIh488"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.8 Feature maps"],"metadata":{"id":"aLsIr6qW0Dgg"}},{"cell_type":"code","source":["import os\n","import keras\n","import numpy as np"],"metadata":{"id":"qx4K8XXcLbNX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visual_folder = os.path.join(save_dir, \"classification_model_visual\")\n","visual_plot_folder = os.path.join(save_dir, \"classification_model_visual_plot\")\n","\n","if not os.path.isdir(visual_folder):\n","  os.makedirs(visual_folder)\n","\n","if not os.path.isdir(visual_plot_folder):\n","  os.makedirs(visual_plot_folder)"],"metadata":{"id":"u5Hk8QNPMv52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visual(model, data, num_layer):\n","  data = np.expand_dims(data, axis=0) \n","  layer = keras.backend.function([model.layers[0].input], [model.layers[num_layer].output])\n","  f1 = layer([data])[0]\n","  num = f1.shape[-1]\n","  plt.figure(figsize=(8, 8))\n","  print(\"saving images in layer_\"+str(num_layer)+\" ...\")\n","  for i in range(num):\n","    plt.subplot(np.ceil(np.sqrt(num)), np.ceil(np.sqrt(num)), i+1)\n","    layer_img = f1[0, :, :, i] * 255\n","    plt.imshow(layer_img, cmap='gray')\n","    plt.axis('off')\n","    visual_single_name = \"layer_\"+str(num_layer)+\"_img_\"+str(i)+\".png\"\n","    layer_single_path = os.path.join(visual_folder, visual_single_name)\n","    cv2.imwrite(layer_single_path, layer_img)\n","  layer_all_name = \"layer_\"+str(num_layer)+\".png\"\n","  layer_all_path = os.path.join(visual_plot_folder, layer_all_name)\n","  plt.savefig(layer_all_path, dpi=350)\n","  plt.show()"],"metadata":{"id":"EX8pM-0m0D2Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(19): \n","  visual(model, X_test[0], i)\n","print(\"All layer images saved!\")"],"metadata":{"id":"T2ana8kr0Qfj"},"execution_count":null,"outputs":[]}]}