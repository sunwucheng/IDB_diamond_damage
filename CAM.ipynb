{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CAM.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPx+yDZQIoA+qzEppSv6H6r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 0 Load dataset"],"metadata":{"id":"A6N5Kh0eQ5Kn"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!nvidia-smi"],"metadata":{"id":"EYpZjshhmXzA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PROJECT_path = '/content/drive/MyDrive/IDB_diamond_damage'"],"metadata":{"id":"dISv84kxL0Qf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from PIL import Image\n","from tqdm import tqdm"],"metadata":{"id":"HgUTma9ZL2GJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_dataset(dataset_path):\n","  image_list = []\n","  label_list = []\n","  tag = 0\n","  category_names = os.listdir(dataset_path)\n","  category_nums = len(category_names)\n","  category_names.sort()\n","  print(category_names)\n","  for category in category_names:\n","    category_path = os.path.join(dataset_path, category)\n","    file_names = os.listdir(category_path)\n","    file_nums = len(file_names)\n","    file_names.sort()  \n","    for file in tqdm(file_names):\n","      file_path = os.path.join(category_path, file)\n","      image = Image.open(file_path)\n","      img = np.asarray(image,dtype=\"float32\")\n","\n","      #chose wheather to crop the images, e.g., 1024*1024\n","      img = img[0:1024, 0:1024]\n","      \n","      img = img[:, :, np.newaxis] \n","      image_list.append(img)\n","      label_list.append(tag)\n","    tag += 1\n","  return image_list, label_list"],"metadata":{"id":"LNebqLzmL3n9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_set, Y_set = load_dataset(os.path.join(PROJECT_path, 'SEM'))"],"metadata":{"id":"kqlxXCUpL34i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CLASS_num = 65\n","CLASS = [\"#01\", \"#02\", \"#03\", \"#04\", \"#05\", \"#06\", \"#07\", \"#08\", \"#09\", \"#10\", \"#11\", \"#12\", \"#13\", \"#14\", \"#15\", \"#16\", \"#17\", \"#18\", \"#19\", \"#20\", \"#21\", \"#22\", \"#23\", \"#24\", \"#25\", \"#26\", \"#27\", \"#28\", \"#29\", \"#30\", \"#31\", \"#32\", \"#33\", \"#34\", \"#35\", \"#36\", \"#37\", \"#38\", \"#39\", \"#40\", \"#41\", \"#42\", \"#43\", \"#44\", \"#45\", \"#46\", \"#47\", \"#48\", \"#49\", \"#50\", \"#51\", \"#52\", \"#53\", \"#54\", \"#55\", \"#56\", \"#57\", \"#58\", \"#59\", \"#60\", \"#61\", \"#62\", \"#63\", \"#64\", \"#65\"]"],"metadata":{"id":"0zAq6lXARmdO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1 Dataset processing"],"metadata":{"id":"xTxeqc04Rrns"}},{"cell_type":"code","source":["def classification_dataset_process(X_set, Y_set):\n","  \n","  # choose the size to convert, e.g., 224*224\n","  X_set = [cv2.cvtColor(cv2.resize(i, (224, 224)), cv2.COLOR_GRAY2RGB) for i in X_set]\n","\n","  X_set = np.asarray(X_set)\n","  X_set = X_set.astype('float32')\n","  X_set /= 255.0\n","  Y_set = tf.keras.utils.to_categorical(Y_set, 65)\n","  return X_set, Y_set"],"metadata":{"id":"UCwcfEwYzfdU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_set, Y_set = classification_dataset_process(X_set, Y_set)"],"metadata":{"id":"5s-GtYtnzgDM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 Grad-CAM algorithms"],"metadata":{"id":"gxVZbHOHRzqD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cx9Pcdj4mHJu"},"outputs":[],"source":["import os\n","import cv2\n","import heapq\n","import keras\n","import tensorflow as tf\n","import numpy as np\n","import tensorflow.keras.backend as K\n","from google.colab.patches import cv2_imshow\n","from tensorflow.keras.applications.vgg16 import (VGG16, preprocess_input, decode_predictions)\n","from tensorflow.keras.models import load_model, Sequential\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.python.framework import ops\n","tf.compat.v1.disable_eager_execution()"]},{"cell_type":"code","source":["model_path = \"/content/drive/MyDrive/IDB_diamond_damage/saved_models/classification_model.h5\"\n","model = load_model(model_path)"],"metadata":{"id":"5blTqMH8uByX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def register_gradient():\n","    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n","        @ops.RegisterGradient(\"GuidedBackProp\")\n","        def _GuidedBackProp(op, grad):\n","            dtype = op.inputs[0].dtype\n","            return grad * tf.cast(grad > 0., dtype) * tf.cast(op.inputs[0] > 0., dtype)\n","\n","def compile_saliency_function(model, activation_layer='block5_conv3'):\n","    input_img = model.input\n","    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n","    layer_output = layer_dict[activation_layer].output\n","    max_output = K.max(layer_output, axis=3)\n","    saliency = K.gradients(K.sum(max_output), input_img)[0]\n","    return K.function([input_img, K.learning_phase()], [saliency])\n","\n","def modify_backprop(model, name):\n","    g = tf.compat.v1.get_default_graph()\n","    with g.gradient_override_map({'Relu': name}):\n","        layer_dict = [layer for layer in model.layers[1:]\n","                      if hasattr(layer, 'activation')]\n","        for layer in layer_dict:\n","            if layer.activation == keras.activations.relu:\n","                layer.activation = tf.nn.relu\n","        new_model = load_model(model_path)\n","    return new_model\n","\n","def deprocess_image(x):\n","    '''\n","    Same normalization as in:\n","    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n","    '''\n","    if np.ndim(x) > 3:\n","        x = np.squeeze(x)\n","    x -= x.mean()\n","    x /= (x.std() + 1e-5)\n","    x *= 0.1\n","    x += 0.5\n","    x = np.clip(x, 0, 1)\n","    x *= 255\n","    if K.image_data_format() == 'channels_first':\n","        x = x.transpose((1, 2, 0))\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x\n","\n","def _compute_gradients(tensor, var_list):\n","    with tf.GradientTape() as gtape:\n","        grads = gtape.gradient(tensor, var_list)\n","        return [grad if grad is not None else tf.zeros_like(var) for var, grad in zip(var_list, grads)]\n","\n","def load_image(path):\n","    img_path = path\n","    img = cv2.imread(img_path)\n","    img = img[0:1024][0:1024]\n","    img= cv2.resize(img,(224,224),interpolation=cv2.INTER_NEAREST)\n","    x = img\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    return x\n","\n","def doCAM(image_path, image_code, dirs1):\n","  preprocessed_input = load_image(image_path)\n","  register_gradient()\n","  guided_model = modify_backprop(model, 'GuidedBackProp')\n","  saliency_fn = compile_saliency_function(guided_model)\n","  saliency = saliency_fn([preprocessed_input, 0])\n","  gradcam = saliency[0].transpose(1, 2, 3, 0)\n","  a = np.squeeze(gradcam)\n","  cv2.imwrite(dirs1+\"/Guided_BP_\"+image_code+\".jpg\", deprocess_image(a))\n","  pred = model.predict(preprocessed_input)\n","  print(np.argmax(pred))\n","  top1_idx, top2_idx, top3_idx= heapq.nlargest(3, range(len(pred[0])), pred[0].take)\n","  class_output = model.output[:, top1_idx]\n","  last_conv_layer = model.get_layer(\"block5_pool\")\n","  grads = K.gradients(class_output, last_conv_layer.output)[0]\n","  pooled_grads = K.mean(grads, axis=(0, 1, 2))\n","  iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n","  pooled_grads_value, conv_layer_output_value = iterate([preprocessed_input])\n","  for i in range(512):\n","      conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n","  heatmap = np.mean(conv_layer_output_value, axis=-1)\n","  heatmap = np.maximum(heatmap, 0)\n","  heatmap /= np.max(heatmap)\n","  img = cv2.imread(image_path)\n","  img = img[0:1024][0:1024]\n","  img= cv2.resize(img,(224,224),interpolation=cv2.INTER_NEAREST)\n","  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n","  heatmap = np.uint8(255 * heatmap)\n","  cv2.imwrite(dirs1+\"/Heatmap_\"+image_code+\".jpg\", heatmap)\n","  heatmap2color = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n","  grd_CAM = cv2.addWeighted(img, 0.6, heatmap2color, 0.4, 0)\n","  cv2.imwrite(dirs1+\"/Grd-CAM_\"+image_code+\".jpg\", grd_CAM)\n","  heatmap =cv2.imread(dirs1+\"/Heatmap_\"+image_code+\".jpg\")\n","  guided_CAM = saliency[0].transpose(1, 2, 3, 0) * heatmap[..., np.newaxis]\n","  guided_CAM = deprocess_image(guided_CAM)\n","  cv2.imwrite(dirs1+\"/Guided-CAM_\"+image_code+\".jpg\", guided_CAM)"],"metadata":{"id":"piONQ628o2L9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 Feature visulization"],"metadata":{"id":"tAF-XCTPpKu1"}},{"cell_type":"code","source":["from keras.models import Model"],"metadata":{"id":"kJqNMH6iNVJb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_set_pred=model.predict(X_set)\n","print(Y_set_pred)"],"metadata":{"id":"wdkkqd4BNWyD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_set_true_label = []\n","for i in range(len(Y_set)):\n","  n = np.argmax(Y_set[i])\n","  Y_set_true_label.append(n)"],"metadata":{"id":"fyRjHtgjNExZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_set_pred_label = []\n","for i in range(len(Y_set_pred)):\n","  n = np.argmax(Y_set_pred[i])\n","  Y_set_pred_label.append(n)"],"metadata":{"id":"7SvJzixaN2QH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Y_set_true_label)\n","print(Y_set)\n","print(Y_set_pred_label)\n","print(Y_set_pred)"],"metadata":{"id":"EDEmdVaGN0pj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_true_set = []\n","for i in range(len(Y_set_pred)):\n","  if Y_set_true_label[i] == Y_set_pred_label[i]:\n","    Y_true_set.append(i)\n","print(Y_true_set)\n","print(len(Y_true_set))"],"metadata":{"id":"CwpqDKvBsv1X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_image_list(dataset_path):\n","  img_path_list = []\n","  category_names = os.listdir(dataset_path)\n","  category_names.sort()\n","  # print(category_names)\n","  category_nums = len(category_names)\n","  images = []\n","  for category in category_names:\n","    category_path = os.path.join(dataset_path, category)\n","    file_names = os.listdir(category_path)\n","    file_names.sort(key=lambda x:int(x[:-5]))\n","    # print(file_names)\n","    file_nums = len(file_names)  \n","    for file in (file_names):\n","      img_path = os.path.join(category_path, file)\n","      img_path_list.append(img_path)\n","  return img_path_list"],"metadata":{"id":"f-w4-J-YpBcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_path_list = load_image_list(\"/content/drive/MyDrive/IDB_diamond_damage/SEM/\")"],"metadata":{"id":"aBCX9vE7qkg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_true_list = []\n","for i in Y_true_set:\n","  Y_true_list.append(image_path_list[i])"],"metadata":{"id":"6RXMH4mUsp8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Y_true_list)"],"metadata":{"id":"W3AyEWwYthPu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dirs1 = \"/content/drive/MyDrive/IDB_diamond_damage/visual\"\n","if not os.path.exists(dirs1):\n","  os.makedirs(dirs1)"],"metadata":{"id":"TqvcUtmnkWZx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for n in range(len(Y_true_list)):\n","  print(\"> \"+str(n))\n","  image_path = Y_true_list[n]\n","  image_code = str(n)\n","  doCAM(image_path, image_code, dirs1)"],"metadata":{"id":"zzKIpXmvsNQN"},"execution_count":null,"outputs":[]}]}